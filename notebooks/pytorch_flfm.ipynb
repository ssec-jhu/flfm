{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2048, 2048]),\n",
       " torch.Size([41, 2048, 2048]),\n",
       " torch.Size([41, 2048, 2048]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def open_image(path: Path) -> torch.Tensor:\n",
    "    img = Image.open(path)\n",
    "    imgs = []\n",
    "    for i in range(img.n_frames):\n",
    "        img.seek(i)\n",
    "        imgs.append(torch.from_numpy(np.array(img).astype(np.float32)))\n",
    "\n",
    "    return torch.stack(imgs, dim=0)\n",
    "\n",
    "\n",
    "# NOTE: The below data files are only present when cloning the repo and not when pip installing the package.\n",
    "image = open_image(\"tests/data/yale/light_field_image.tif\").to(device)\n",
    "measured_psf = open_image(\"tests/data/yale/measured_psf.tif\").to(device)\n",
    "mirrored_psf = torch.flip(measured_psf, dims=(-2, -1)).to(device)\n",
    "\n",
    "image.shape, measured_psf.shape, mirrored_psf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.compile\n",
    "def compute_step_f(\n",
    "    data: torch.Tensor,  # [k, n, n]\n",
    "    image: torch.Tensor,  # [1, n, n]\n",
    "    PSF_fft: torch.Tensor,  # [k, n, n/2+1]\n",
    "    PSFt_fft: torch.Tensor,  # [k, n, n/2+1]\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Single step of the multiplicative Richardson-Lucy deconvolution algorithm.\"\"\"\n",
    "    denom = torch.fft.irfft2(PSF_fft * torch.fft.rfft2(data), dim=(-2, -1)).sum(dim=0, keepdim=True)  # [1, n, n]\n",
    "    img_err = image / denom\n",
    "    return data * torch.fft.fftshift(torch.fft.irfft2(torch.fft.rfft2(img_err) * PSFt_fft), dim=(-2, -1))  # [k, n, n]\n",
    "\n",
    "\n",
    "jitted_fn = torch.jit.script(compute_step_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([41, 2048, 2048]),\n",
       " torch.Size([41, 2048, 1025]),\n",
       " torch.Size([41, 2048, 1025]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess = (torch.ones_like(measured_psf) * 0.5).to(device)  # [k, n, n]\n",
    "\n",
    "psf_fft = torch.fft.rfft2(measured_psf, dim=(-2, -1)).to(device)  # [k, n, n/2+1]\n",
    "psft_fft = torch.fft.rfft2(mirrored_psf, dim=(-2, -1)).to(device)  # [k, n, n/2+1]\n",
    "\n",
    "guess.shape, psf_fft.shape, psft_fft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.004533052444458008 seconds\n",
      "Time taken: 0.0034372806549072266 seconds\n",
      "Time taken: 0.0006814002990722656 seconds\n",
      "Time taken: 0.0006372928619384766 seconds\n",
      "Time taken: 0.0006268024444580078 seconds\n",
      "Time taken: 0.0006577968597412109 seconds\n",
      "Time taken: 0.0006549358367919922 seconds\n",
      "Time taken: 0.0006091594696044922 seconds\n",
      "Time taken: 0.0006577968597412109 seconds\n",
      "Time taken: 0.0005857944488525391 seconds\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    start = time.time()\n",
    "    guess = jitted_fn(guess, image, psf_fft, psft_fft)\n",
    "    print(f\"Time taken: {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(jitted_fn, \"richardson_lucy_step.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_fn = torch.jit.load(\"richardson_lucy_step.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.00412750244140625 seconds\n",
      "Time taken: 0.0041065216064453125 seconds\n",
      "Time taken: 0.0007188320159912109 seconds\n",
      "Time taken: 0.0006849765777587891 seconds\n",
      "Time taken: 0.0006461143493652344 seconds\n",
      "Time taken: 0.0006556510925292969 seconds\n",
      "Time taken: 0.0006611347198486328 seconds\n",
      "Time taken: 0.0006539821624755859 seconds\n",
      "Time taken: 0.0006382465362548828 seconds\n",
      "Time taken: 0.0006551742553710938 seconds\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    start = time.time()\n",
    "    guess = loaded_fn(guess, image, psf_fft, psft_fft)\n",
    "    print(f\"Time taken: {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_circle_mask(\n",
    "    radius: int,\n",
    ") -> np.ndarray:\n",
    "    y, x = np.ogrid[: 2 * radius, : 2 * radius]\n",
    "    circle_mask = (x - radius) ** 2 + (y - radius) ** 2 <= radius**2\n",
    "    return circle_mask.astype(np.float32)\n",
    "\n",
    "\n",
    "def post_processing(\n",
    "    O: np.ndarray,  # noqa: E741\n",
    "    center: tuple[int, int],\n",
    "    radius: int,\n",
    ") -> np.ndarray:\n",
    "    circle_mask = np.expand_dims(make_circle_mask(radius), axis=0)\n",
    "    sub_o = O[:, center[0] - radius : center[0] + radius, center[1] - radius : center[1] + radius]\n",
    "    return sub_o * circle_mask\n",
    "\n",
    "\n",
    "proc_guess = post_processing(guess.detach().cpu().numpy(), (1000, 980), 230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(np.array(proc_guess[0]))\n",
    "img.save(\n",
    "    \"pytorch_img.tif\",\n",
    "    format=\"tiff\",\n",
    "    append_images=[Image.fromarray(np.array(proc_guess[i])) for i in range(1, len(proc_guess))],\n",
    "    save_all=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flfm-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
